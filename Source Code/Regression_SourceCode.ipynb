{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28siEEloi0So",
        "outputId": "184a237d-de1f-44e1-beb3-a30047608bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "qgTaUB4hPSwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import os"
      ],
      "metadata": {
        "id": "N_54wk2GPSA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dljq5e87kBrN"
      },
      "source": [
        "# Coli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HASTEVgKizFc"
      },
      "outputs": [],
      "source": [
        "input_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/filtered_data/filtered_coli.csv\"  # Update with your file path\n",
        "df = pd.read_csv(input_path)\n",
        "df = df.dropna(subset=[\"Sequence\", \"Cleaned_MIC\"])\n",
        "df[\"Sequence\"] = df[\"Sequence\"].str.upper().str.replace(\"[^ACDEFGHIKLMNPQRSTVWY]\", \"\", regex=True)\n",
        "df = df[df[\"Sequence\"].str.len() > 10].reset_index(drop=True)\n",
        "\n",
        "# Load ProtBERT\n",
        "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
        "model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device).eval()\n",
        "\n",
        "embedding_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/coli_protbert_embeddings.npy\"\n",
        "target_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/coli_mic_targets.npy\"\n",
        "\n",
        "def embed_sequence(seq):\n",
        "    seq = \" \".join(list(seq))\n",
        "    tokens = tokenizer(seq, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=512)\n",
        "    with torch.no_grad():\n",
        "        output = model(**{k: v.to(device) for k, v in tokens.items()})\n",
        "    return output.last_hidden_state.mean(1).squeeze().cpu().numpy()\n",
        "\n",
        "if os.path.exists(embedding_path) and os.path.exists(target_path):\n",
        "    print(\"Loading existing embeddings...\")\n",
        "    embeddings = np.load(embedding_path)\n",
        "    targets = np.load(target_path)\n",
        "else:\n",
        "    print(\"Embedding sequences with ProtBERT...\")\n",
        "    embeddings = []\n",
        "    for i, seq in enumerate(tqdm(df[\"Sequence\"])):\n",
        "        emb = embed_sequence(seq)\n",
        "        embeddings.append(emb)\n",
        "        if i % 100 == 0:\n",
        "            np.save(embedding_path, np.vstack(embeddings))\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    np.save(embedding_path, embeddings)\n",
        "    targets = np.log1p(df[\"Cleaned_MIC\"].values)\n",
        "    np.save(target_path, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXh11014kFKp"
      },
      "source": [
        "# Aur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UuGbIukkHTF"
      },
      "outputs": [],
      "source": [
        "input_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/filtered_data/filtered_aur.csv\"  # Update with your file path\n",
        "df = pd.read_csv(input_path)\n",
        "df = df.dropna(subset=[\"Sequence\", \"Cleaned_MIC\"])\n",
        "df[\"Sequence\"] = df[\"Sequence\"].str.upper().str.replace(\"[^ACDEFGHIKLMNPQRSTVWY]\", \"\", regex=True)\n",
        "df = df[df[\"Sequence\"].str.len() > 10].reset_index(drop=True)\n",
        "\n",
        "# Load ProtBERT\n",
        "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
        "model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device).eval()\n",
        "\n",
        "embedding_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/aur_protbert_embeddings.npy\"\n",
        "target_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/aur_mic_targets.npy\"\n",
        "\n",
        "def embed_sequence(seq):\n",
        "    seq = \" \".join(list(seq))\n",
        "    tokens = tokenizer(seq, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=512)\n",
        "    with torch.no_grad():\n",
        "        output = model(**{k: v.to(device) for k, v in tokens.items()})\n",
        "    return output.last_hidden_state.mean(1).squeeze().cpu().numpy()\n",
        "\n",
        "if os.path.exists(embedding_path) and os.path.exists(target_path):\n",
        "    print(\"Loading existing embeddings...\")\n",
        "    embeddings = np.load(embedding_path)\n",
        "    targets = np.load(target_path)\n",
        "else:\n",
        "    print(\"Embedding sequences with ProtBERT...\")\n",
        "    embeddings = []\n",
        "    for i, seq in enumerate(tqdm(df[\"Sequence\"])):\n",
        "        emb = embed_sequence(seq)\n",
        "        embeddings.append(emb)\n",
        "        if i % 100 == 0:\n",
        "            np.save(embedding_path, np.vstack(embeddings))\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    np.save(embedding_path, embeddings)\n",
        "    targets = np.log1p(df[\"Cleaned_MIC\"].values)\n",
        "    np.save(target_path, targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5DAfw-KkHz6"
      },
      "source": [
        "# Arg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdL6x2yWkJWc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import os\n",
        "\n",
        "input_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/filtered_data/filtered_arg.csv\"  # Update with your file path\n",
        "df = pd.read_csv(input_path)\n",
        "df = df.dropna(subset=[\"Sequence\", \"Cleaned_MIC\"])\n",
        "df[\"Sequence\"] = df[\"Sequence\"].str.upper().str.replace(\"[^ACDEFGHIKLMNPQRSTVWY]\", \"\", regex=True)\n",
        "df = df[df[\"Sequence\"].str.len() > 10].reset_index(drop=True)\n",
        "\n",
        "# Load ProtBERT\n",
        "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
        "model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device).eval()\n",
        "\n",
        "embedding_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/arg_protbert_embeddings.npy\"\n",
        "target_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/arg_mic_targets.npy\"\n",
        "\n",
        "def embed_sequence(seq):\n",
        "    seq = \" \".join(list(seq))\n",
        "    tokens = tokenizer(seq, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=512)\n",
        "    with torch.no_grad():\n",
        "        output = model(**{k: v.to(device) for k, v in tokens.items()})\n",
        "    return output.last_hidden_state.mean(1).squeeze().cpu().numpy()\n",
        "\n",
        "if os.path.exists(embedding_path) and os.path.exists(target_path):\n",
        "    print(\"Loading existing embeddings...\")\n",
        "    embeddings = np.load(embedding_path)\n",
        "    targets = np.load(target_path)\n",
        "else:\n",
        "    print(\"Embedding sequences with ProtBERT...\")\n",
        "    embeddings = []\n",
        "    for i, seq in enumerate(tqdm(df[\"Sequence\"])):\n",
        "        emb = embed_sequence(seq)\n",
        "        embeddings.append(emb)\n",
        "        if i % 100 == 0:\n",
        "            np.save(embedding_path, np.vstack(embeddings))\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    np.save(embedding_path, embeddings)\n",
        "    targets = np.log1p(df[\"Cleaned_MIC\"].values)\n",
        "    np.save(target_path, targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O02M6HMqkJpo"
      },
      "source": [
        "# Pne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q8-hJvXkK9u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import os\n",
        "\n",
        "input_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/filtered_data/filtered_pne.csv\"  # Update with your file path\n",
        "df = pd.read_csv(input_path)\n",
        "df = df.dropna(subset=[\"Sequence\", \"Cleaned_MIC\"])\n",
        "df[\"Sequence\"] = df[\"Sequence\"].str.upper().str.replace(\"[^ACDEFGHIKLMNPQRSTVWY]\", \"\", regex=True)\n",
        "df = df[df[\"Sequence\"].str.len() > 10].reset_index(drop=True)\n",
        "\n",
        "# Load ProtBERT\n",
        "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
        "model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device).eval()\n",
        "\n",
        "embedding_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/pne_protbert_embeddings.npy\"\n",
        "target_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/pne_mic_targets.npy\"\n",
        "\n",
        "def embed_sequence(seq):\n",
        "    seq = \" \".join(list(seq))\n",
        "    tokens = tokenizer(seq, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=512)\n",
        "    with torch.no_grad():\n",
        "        output = model(**{k: v.to(device) for k, v in tokens.items()})\n",
        "    return output.last_hidden_state.mean(1).squeeze().cpu().numpy()\n",
        "\n",
        "if os.path.exists(embedding_path) and os.path.exists(target_path):\n",
        "    print(\"Loading existing embeddings...\")\n",
        "    embeddings = np.load(embedding_path)\n",
        "    targets = np.load(target_path)\n",
        "else:\n",
        "    print(\"ðŸ”„ Embedding sequences with ProtBERT...\")\n",
        "    embeddings = []\n",
        "    for i, seq in enumerate(tqdm(df[\"Sequence\"])):\n",
        "        emb = embed_sequence(seq)\n",
        "        embeddings.append(emb)\n",
        "        if i % 100 == 0:\n",
        "            np.save(embedding_path, np.vstack(embeddings))\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    np.save(embedding_path, embeddings)\n",
        "    targets = np.log1p(df[\"Cleaned_MIC\"].values)\n",
        "    np.save(target_path, targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2ojmZrplcsw"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opSesJzkleDQ"
      },
      "source": [
        "## Coli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh-DpLsYTIps"
      },
      "outputs": [],
      "source": [
        "embedding_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/coli_protbert_embeddings.npy\"\n",
        "target_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/coli_mic_targets.npy\"\n",
        "\n",
        "file_name = os.path.basename(embedding_path)\n",
        "organism_code = file_name.split(\"_\")[0].lower()\n",
        "organism_names = {\n",
        "    \"pne\": \"Pneumonia\",\n",
        "    \"aur\": \"Staphylococcus aureus\",\n",
        "    \"coli\": \"E. coli\",\n",
        "    \"arg\": \"Pseudomonas aeruginosa\"\n",
        "}\n",
        "organism = organism_names.get(organism_code, organism_code.upper())\n",
        "\n",
        "\n",
        "X = np.load(embedding_path)\n",
        "y = np.load(target_path)\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test, y_train_log, y_test_log = train_test_split(\n",
        "    X, y, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "results = {}\n",
        "predictions = {}\n",
        "\n",
        "def evaluate_model(model, model_name, X_train_input, X_test_input):\n",
        "    model.fit(X_train_input, y_train)\n",
        "    y_pred = model.predict(X_test_input)\n",
        "\n",
        "    mse_log = mean_squared_error(y_test_log, np.log1p(y_pred))\n",
        "    mse_no_log = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test_log, np.log1p(y_pred))\n",
        "    mae = mean_absolute_error(y_test_log, np.log1p(y_pred))\n",
        "    pearson, _ = pearsonr(y_test_log, np.log1p(y_pred))\n",
        "    kendall, _ = kendalltau(y_test_log, np.log1p(y_pred))\n",
        "\n",
        "    results[model_name] = {\n",
        "        'MSE(log)': mse_log, 'MSE': mse_no_log, 'R2': r2,\n",
        "        'MAE': mae, 'Pearson': pearson, 'Kendall': kendall\n",
        "    }\n",
        "    predictions[model_name] = y_pred\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"MSE(log): {mse_log:.4f}, MSE: {mse_no_log:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}, Pearson: {pearson:.4f}, Kendall: {kendall:.4f}\")\n",
        "\n",
        "\n",
        "evaluate_model(SVR(kernel='rbf'), \"SVR\", X_train_pca, X_test_pca)\n",
        "evaluate_model(RandomForestRegressor(n_estimators=100, random_state=42), \"Random Forest\", X_train, X_test)\n",
        "evaluate_model(xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42), \"XGBoost\", X_train, X_test)\n",
        "evaluate_model(MLPRegressor(hidden_layer_sizes=(512, 128), max_iter=500, random_state=42), \"MLP\", X_train_pca, X_test_pca)\n",
        "\n",
        "\n",
        "df_results = pd.DataFrame(results).T\n",
        "df_results['R2_rank'] = df_results['R2'].rank(ascending=False)\n",
        "df_results['MSE_rank'] = df_results['MSE'].rank(ascending=True)\n",
        "df_results['Combined_rank'] = df_results['R2_rank'] + df_results['MSE_rank']\n",
        "best_model_name = df_results['Combined_rank'].idxmin()\n",
        "\n",
        "# Save results\n",
        "save_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/results/coli_model_evaluation_results.csv\"\n",
        "df_results.to_csv(save_path, index=True)\n",
        "print(f\"\\nBest model based on RÂ² + MSE: {best_model_name}\")\n",
        "print(f\"Results saved to {save_path}\")\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "metrics = ['MSE(log)', 'R2', 'MAE', 'Pearson']\n",
        "for ax, metric in zip(axes.flatten(), metrics):\n",
        "    sns.barplot(x=df_results.index, y=df_results[metric], ax=ax)\n",
        "    ax.set_title(f'{metric} Comparison on {organism}')\n",
        "    ax.set_ylabel(metric)\n",
        "    ax.set_xlabel('Model')\n",
        "    ax.set_xticklabels(df_results.index, rotation=45)\n",
        "    ax.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "y_pred = predictions[best_model_name]\n",
        "y_true_log = np.log1p(y_test)\n",
        "y_pred_log = np.log1p(y_pred)\n",
        "residuals = y_pred_log - y_true_log\n",
        "\n",
        "# Scatter Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.scatterplot(x=y_true_log, y=y_pred_log)\n",
        "plt.plot([min(y_true_log), max(y_true_log)], [min(y_true_log), max(y_true_log)], 'r--')\n",
        "plt.xlabel(\"True MIC (log)\")\n",
        "plt.ylabel(\"Predicted MIC (log)\")\n",
        "plt.title(f\"{best_model_name} on {organism}: True vs. Predicted MIC (log)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Residuals\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(residuals, kde=True, color='purple')\n",
        "plt.axvline(0, color='red', linestyle='--')\n",
        "plt.title(f\"{best_model_name} on {organism}: Residual Distribution (log scale)\")\n",
        "plt.xlabel(\"Residual\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bland-Altman\n",
        "mean_values = (y_true_log + y_pred_log) / 2\n",
        "diff = y_pred_log - y_true_log\n",
        "mean_diff = np.mean(diff)\n",
        "std_diff = np.std(diff)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(mean_values, diff, alpha=0.6)\n",
        "plt.axhline(mean_diff, color='gray', linestyle='--', label=\"Mean Diff\")\n",
        "plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label=\"Â±1.96 SD\")\n",
        "plt.axhline(mean_diff - 1.96 * std_diff, color='red', linestyle='--')\n",
        "plt.title(f\"{best_model_name} on {organism}: Bland-Altman Plot\")\n",
        "plt.xlabel(\"Mean of True & Predicted (log MIC)\")\n",
        "plt.ylabel(\"Difference (Pred - True)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPmR5j9alghY"
      },
      "source": [
        "## Aur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMiQ5PHPliY5"
      },
      "outputs": [],
      "source": [
        "embedding_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/aur_protbert_embeddings.npy\"\n",
        "target_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/aur_mic_targets.npy\"\n",
        "\n",
        "file_name = os.path.basename(embedding_path)\n",
        "organism_code = file_name.split(\"_\")[0].lower()\n",
        "organism_names = {\n",
        "    \"pne\": \"Pneumonia\",\n",
        "    \"aur\": \"Staphylococcus aureus\",\n",
        "    \"coli\": \"E. coli\",\n",
        "    \"arg\": \"Pseudomonas aeruginosa\"\n",
        "}\n",
        "organism = organism_names.get(organism_code, organism_code.upper())\n",
        "\n",
        "\n",
        "X = np.load(embedding_path)\n",
        "y = np.load(target_path)\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test, y_train_log, y_test_log = train_test_split(\n",
        "    X, y, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "results = {}\n",
        "predictions = {}\n",
        "\n",
        "def evaluate_model(model, model_name, X_train_input, X_test_input):\n",
        "    model.fit(X_train_input, y_train)\n",
        "    y_pred = model.predict(X_test_input)\n",
        "\n",
        "    mse_log = mean_squared_error(y_test_log, np.log1p(y_pred))\n",
        "    mse_no_log = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test_log, np.log1p(y_pred))\n",
        "    mae = mean_absolute_error(y_test_log, np.log1p(y_pred))\n",
        "    pearson, _ = pearsonr(y_test_log, np.log1p(y_pred))\n",
        "    kendall, _ = kendalltau(y_test_log, np.log1p(y_pred))\n",
        "\n",
        "    results[model_name] = {\n",
        "        'MSE(log)': mse_log, 'MSE': mse_no_log, 'R2': r2,\n",
        "        'MAE': mae, 'Pearson': pearson, 'Kendall': kendall\n",
        "    }\n",
        "    predictions[model_name] = y_pred\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"MSE(log): {mse_log:.4f}, MSE: {mse_no_log:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}, Pearson: {pearson:.4f}, Kendall: {kendall:.4f}\")\n",
        "\n",
        "\n",
        "print(\"Training and evaluating SVR...\")\n",
        "evaluate_model(SVR(kernel='rbf'), \"SVR\", X_train_pca, X_test_pca)\n",
        "\n",
        "print(\"Training and evaluating Random Forest...\")\n",
        "evaluate_model(RandomForestRegressor(n_estimators=100, random_state=42), \"Random Forest\", X_train, X_test)\n",
        "\n",
        "print(\"Training and evaluating XGBoost...\")\n",
        "evaluate_model(xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42), \"XGBoost\", X_train, X_test)\n",
        "\n",
        "print(\"Training and evaluating MLP...\")\n",
        "evaluate_model(MLPRegressor(hidden_layer_sizes=(512, 128), max_iter=500, random_state=42), \"MLP\", X_train_pca, X_test_pca)\n",
        "\n",
        "\n",
        "df_results = pd.DataFrame(results).T\n",
        "df_results['R2_rank'] = df_results['R2'].rank(ascending=False)\n",
        "df_results['MSE_rank'] = df_results['MSE'].rank(ascending=True)\n",
        "df_results['Combined_rank'] = df_results['R2_rank'] + df_results['MSE_rank']\n",
        "best_model_name = df_results['Combined_rank'].idxmin()\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/results/aur_model_evaluation_results.csv\"\n",
        "df_results.to_csv(save_path, index=True)\n",
        "print(f\"\\nBest model based on RÂ² + MSE: {best_model_name}\")\n",
        "print(f\"Results saved to {save_path}\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "metrics = ['MSE(log)', 'R2', 'MAE', 'Pearson']\n",
        "\n",
        "for ax, metric in zip(axes.flatten(), metrics):\n",
        "    sns.barplot(x=df_results.index, y=df_results[metric], ax=ax)\n",
        "    ax.set_title(f'{metric} Comparison on {organism}')\n",
        "    ax.set_ylabel(metric)\n",
        "    ax.set_xlabel('Model')\n",
        "    ax.set_xticklabels(df_results.index, rotation=45)\n",
        "    ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "y_pred = predictions[best_model_name]\n",
        "y_true_log = np.log1p(y_test)\n",
        "y_pred_log = np.log1p(y_pred)\n",
        "residuals = y_pred_log - y_true_log\n",
        "\n",
        "# Scatter Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.scatterplot(x=y_true_log, y=y_pred_log)\n",
        "plt.plot([min(y_true_log), max(y_true_log)], [min(y_true_log), max(y_true_log)], 'r--')\n",
        "plt.xlabel(\"True MIC (log)\")\n",
        "plt.ylabel(\"Predicted MIC (log)\")\n",
        "plt.title(f\"{best_model_name} on {organism}: True vs. Predicted MIC (log)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Residuals\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(residuals, kde=True, color='purple')\n",
        "plt.axvline(0, color='red', linestyle='--')\n",
        "plt.title(f\"{best_model_name} on {organism}: Residual Distribution (log scale)\")\n",
        "plt.xlabel(\"Residual\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bland-Altman\n",
        "mean_values = (y_true_log + y_pred_log) / 2\n",
        "diff = y_pred_log - y_true_log\n",
        "mean_diff = np.mean(diff)\n",
        "std_diff = np.std(diff)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(mean_values, diff, alpha=0.6)\n",
        "plt.axhline(mean_diff, color='gray', linestyle='--', label=\"Mean Diff\")\n",
        "plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label=\"Â±1.96 SD\")\n",
        "plt.axhline(mean_diff - 1.96 * std_diff, color='red', linestyle='--')\n",
        "plt.title(f\"{best_model_name} on {organism}: Bland-Altman Plot\")\n",
        "plt.xlabel(\"Mean of True & Predicted (log MIC)\")\n",
        "plt.ylabel(\"Difference (Pred - True)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr0Mbbh-lirY"
      },
      "source": [
        "## Arg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ey4Jm1mMlj8o"
      },
      "outputs": [],
      "source": [
        "embedding_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/arg_protbert_embeddings.npy\"\n",
        "target_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/arg_mic_targets.npy\"\n",
        "\n",
        "file_name = os.path.basename(embedding_path)\n",
        "organism_code = file_name.split(\"_\")[0].lower()\n",
        "organism_names = {\n",
        "    \"pne\": \"Pneumonia\",\n",
        "    \"aur\": \"Staphylococcus aureus\",\n",
        "    \"coli\": \"E. coli\",\n",
        "    \"arg\": \"Pseudomonas aeruginosa\"\n",
        "}\n",
        "organism = organism_names.get(organism_code, organism_code.upper())\n",
        "\n",
        "\n",
        "X = np.load(embedding_path)\n",
        "y = np.load(target_path)\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test, y_train_log, y_test_log = train_test_split(\n",
        "    X, y, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "results = {}\n",
        "predictions = {}\n",
        "\n",
        "def evaluate_model(model, model_name, X_train_input, X_test_input):\n",
        "    model.fit(X_train_input, y_train)\n",
        "    y_pred = model.predict(X_test_input)\n",
        "\n",
        "    mse_log = mean_squared_error(y_test_log, np.log1p(y_pred))\n",
        "    mse_no_log = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test_log, np.log1p(y_pred))\n",
        "    mae = mean_absolute_error(y_test_log, np.log1p(y_pred))\n",
        "    pearson, _ = pearsonr(y_test_log, np.log1p(y_pred))\n",
        "    kendall, _ = kendalltau(y_test_log, np.log1p(y_pred))\n",
        "\n",
        "    results[model_name] = {\n",
        "        'MSE(log)': mse_log, 'MSE': mse_no_log, 'R2': r2,\n",
        "        'MAE': mae, 'Pearson': pearson, 'Kendall': kendall\n",
        "    }\n",
        "\n",
        "    predictions[model_name] = y_pred\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"MSE(log): {mse_log:.4f}, MSE: {mse_no_log:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}, Pearson: {pearson:.4f}, Kendall: {kendall:.4f}\")\n",
        "\n",
        "\n",
        "print(\"Training and evaluating SVR...\")\n",
        "evaluate_model(SVR(kernel='rbf'), \"SVR\", X_train_pca, X_test_pca)\n",
        "\n",
        "print(\"Training and evaluating Random Forest Regressor...\")\n",
        "evaluate_model(RandomForestRegressor(n_estimators=100, random_state=42), \"Random Forest\", X_train, X_test)\n",
        "\n",
        "print(\"Training and evaluating XGBoost...\")\n",
        "evaluate_model(xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42), \"XGBoost\", X_train, X_test)\n",
        "\n",
        "print(\"Training and evaluating MLP Regressor...\")\n",
        "evaluate_model(MLPRegressor(hidden_layer_sizes=(512, 128), max_iter=500, random_state=42), \"MLP\", X_train_pca, X_test_pca)\n",
        "\n",
        "\n",
        "df_results = pd.DataFrame(results).T\n",
        "df_results['R2_rank'] = df_results['R2'].rank(ascending=False)\n",
        "df_results['MSE_rank'] = df_results['MSE'].rank(ascending=True)\n",
        "df_results['Combined_rank'] = df_results['R2_rank'] + df_results['MSE_rank']\n",
        "best_model_name = df_results['Combined_rank'].idxmin()\n",
        "\n",
        "results_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/results/arg_model_evaluation_results.csv\"\n",
        "df_results.to_csv(results_path, index=True)\n",
        "print(f\"\\nBest model based on RÂ² + MSE: {best_model_name}\")\n",
        "print(f\"Results saved to: {results_path}\")\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "metrics = ['MSE(log)', 'R2', 'MAE', 'Pearson']\n",
        "\n",
        "for ax, metric in zip(axes.flatten(), metrics):\n",
        "    sns.barplot(x=df_results.index, y=df_results[metric], ax=ax)\n",
        "    ax.set_title(f'{metric} Comparison on {organism}')\n",
        "    ax.set_ylabel(metric)\n",
        "    ax.set_xlabel('Model')\n",
        "    ax.set_xticklabels(df_results.index, rotation=45)\n",
        "    ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "y_pred = predictions[best_model_name]\n",
        "y_true_log = np.log1p(y_test)\n",
        "y_pred_log = np.log1p(y_pred)\n",
        "residuals = y_pred_log - y_true_log\n",
        "\n",
        "# Scatter Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.scatterplot(x=y_true_log, y=y_pred_log)\n",
        "plt.plot([min(y_true_log), max(y_true_log)], [min(y_true_log), max(y_true_log)], 'r--')\n",
        "plt.xlabel(\"True MIC (log)\")\n",
        "plt.ylabel(\"Predicted MIC (log)\")\n",
        "plt.title(f\"{best_model_name} on {organism}: True vs. Predicted MIC (log)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Residual Plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(residuals, kde=True, color='purple')\n",
        "plt.axvline(0, color='red', linestyle='--')\n",
        "plt.title(f\"{best_model_name} on {organism}: Residual Distribution (log scale)\")\n",
        "plt.xlabel(\"Residual\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bland-Altman Plot\n",
        "mean_values = (y_true_log + y_pred_log) / 2\n",
        "diff = y_pred_log - y_true_log\n",
        "mean_diff = np.mean(diff)\n",
        "std_diff = np.std(diff)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(mean_values, diff, alpha=0.6)\n",
        "plt.axhline(mean_diff, color='gray', linestyle='--', label=\"Mean Diff\")\n",
        "plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label=\"Â±1.96 SD\")\n",
        "plt.axhline(mean_diff - 1.96 * std_diff, color='red', linestyle='--')\n",
        "plt.title(f\"{best_model_name} on {organism}: Bland-Altman Plot\")\n",
        "plt.xlabel(\"Mean of True & Predicted (log MIC)\")\n",
        "plt.ylabel(\"Difference (Pred - True)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiRZg6fklkVz"
      },
      "source": [
        "## Pne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRqjPaGalls2"
      },
      "outputs": [],
      "source": [
        "embedding_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/pne_protbert_embeddings.npy\"\n",
        "target_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/pne_mic_targets.npy\"\n",
        "\n",
        "file_name = os.path.basename(embedding_path)\n",
        "organism_code = file_name.split(\"_\")[0].lower()\n",
        "organism_names = {\n",
        "    \"pne\": \"Pneumonia\",\n",
        "    \"aur\": \"Staphylococcus aureus\",\n",
        "    \"coli\": \"E. coli\",\n",
        "    \"arg\": \"Pseudomonas aeruginosa\"\n",
        "}\n",
        "organism = organism_names.get(organism_code, organism_code.upper())\n",
        "\n",
        "\n",
        "X = np.load(embedding_path)\n",
        "y = np.load(target_path)\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test, y_train_log, y_test_log = train_test_split(\n",
        "    X, y, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "results = {}\n",
        "predictions = {}\n",
        "\n",
        "def evaluate_model(model, model_name, X_train_input, X_test_input):\n",
        "    model.fit(X_train_input, y_train)\n",
        "    y_pred = model.predict(X_test_input)\n",
        "\n",
        "    mse_log = mean_squared_error(y_test_log, np.log1p(y_pred))\n",
        "    mse_no_log = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test_log, np.log1p(y_pred))\n",
        "    mae = mean_absolute_error(y_test_log, np.log1p(y_pred))\n",
        "    pearson, _ = pearsonr(y_test_log, np.log1p(y_pred))\n",
        "    kendall, _ = kendalltau(y_test_log, np.log1p(y_pred))\n",
        "\n",
        "    results[model_name] = {\n",
        "        'MSE(log)': mse_log, 'MSE': mse_no_log, 'R2': r2,\n",
        "        'MAE': mae, 'Pearson': pearson, 'Kendall': kendall\n",
        "    }\n",
        "    predictions[model_name] = y_pred\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"MSE(log): {mse_log:.4f}, MSE: {mse_no_log:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}, Pearson: {pearson:.4f}, Kendall: {kendall:.4f}\")\n",
        "\n",
        "\n",
        "print(\"Training and evaluating SVR...\")\n",
        "evaluate_model(SVR(kernel='rbf'), \"SVR\", X_train_pca, X_test_pca)\n",
        "\n",
        "print(\"Training and evaluating Random Forest Regressor...\")\n",
        "evaluate_model(RandomForestRegressor(n_estimators=100, random_state=42), \"Random Forest\", X_train, X_test)\n",
        "\n",
        "print(\"Training and evaluating XGBoost...\")\n",
        "evaluate_model(xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42), \"XGBoost\", X_train, X_test)\n",
        "\n",
        "print(\"Training and evaluating MLP Regressor...\")\n",
        "evaluate_model(MLPRegressor(hidden_layer_sizes=(512, 128), max_iter=500, random_state=42), \"MLP\", X_train_pca, X_test_pca)\n",
        "\n",
        "df_results = pd.DataFrame(results).T\n",
        "df_results['R2_rank'] = df_results['R2'].rank(ascending=False)\n",
        "df_results['MSE_rank'] = df_results['MSE'].rank(ascending=True)\n",
        "df_results['Combined_rank'] = df_results['R2_rank'] + df_results['MSE_rank']\n",
        "best_model_name = df_results['Combined_rank'].idxmin()\n",
        "\n",
        "results_path = \"/content/drive/MyDrive/AMPs/Project Data/Regression Part/results/pne_model_evaluation_results.csv\"\n",
        "df_results.to_csv(results_path, index=True)\n",
        "print(f\"\\nBest model based on RÂ² + MSE: {best_model_name}\")\n",
        "print(f\"Results saved to: {results_path}\")\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "metrics = ['MSE(log)', 'R2', 'MAE', 'Pearson']\n",
        "\n",
        "for ax, metric in zip(axes.flatten(), metrics):\n",
        "    sns.barplot(x=df_results.index, y=df_results[metric], ax=ax)\n",
        "    ax.set_title(f'{metric} Comparison on {organism}')\n",
        "    ax.set_ylabel(metric)\n",
        "    ax.set_xlabel('Model')\n",
        "    ax.set_xticklabels(df_results.index, rotation=45)\n",
        "    ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "y_pred = predictions[best_model_name]\n",
        "y_true_log = np.log1p(y_test)\n",
        "y_pred_log = np.log1p(y_pred)\n",
        "residuals = y_pred_log - y_true_log\n",
        "\n",
        "# Scatter Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.scatterplot(x=y_true_log, y=y_pred_log)\n",
        "plt.plot([min(y_true_log), max(y_true_log)], [min(y_true_log), max(y_true_log)], 'r--')\n",
        "plt.xlabel(\"True MIC (log)\")\n",
        "plt.ylabel(\"Predicted MIC (log)\")\n",
        "plt.title(f\"{best_model_name} on {organism}: True vs. Predicted MIC (log)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Residuals Plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(residuals, kde=True, color='purple')\n",
        "plt.axvline(0, color='red', linestyle='--')\n",
        "plt.title(f\"{best_model_name} on {organism}: Residual Distribution (log scale)\")\n",
        "plt.xlabel(\"Residual\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bland-Altman Plot\n",
        "mean_values = (y_true_log + y_pred_log) / 2\n",
        "diff = y_pred_log - y_true_log\n",
        "mean_diff = np.mean(diff)\n",
        "std_diff = np.std(diff)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(mean_values, diff, alpha=0.6)\n",
        "plt.axhline(mean_diff, color='gray', linestyle='--', label=\"Mean Diff\")\n",
        "plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label=\"Â±1.96 SD\")\n",
        "plt.axhline(mean_diff - 1.96 * std_diff, color='red', linestyle='--')\n",
        "plt.title(f\"{best_model_name} on {organism}: Bland-Altman Plot\")\n",
        "plt.xlabel(\"Mean of True & Predicted (log MIC)\")\n",
        "plt.ylabel(\"Difference (Pred - True)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}