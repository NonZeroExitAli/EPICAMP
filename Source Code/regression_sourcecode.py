# -*- coding: utf-8 -*-
"""Regression_SourceCode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wp-usSN67Dlqrby26o3ezns6Lem5vwEv
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Importing libraries"""

import pandas as pd
import numpy as np
from tqdm import tqdm
from transformers import BertTokenizer, BertModel
import torch
import os

"""# Coli"""

input_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/filtered_data/filtered_coli.csv"  # Update with your file path
df = pd.read_csv(input_path)
df = df.dropna(subset=["Sequence", "Cleaned_MIC"])
df["Sequence"] = df["Sequence"].str.upper().str.replace("[^ACDEFGHIKLMNPQRSTVWY]", "", regex=True)
df = df[df["Sequence"].str.len() > 10].reset_index(drop=True)

# Load ProtBERT
tokenizer = BertTokenizer.from_pretrained("Rostlab/prot_bert", do_lower_case=False)
model = BertModel.from_pretrained("Rostlab/prot_bert")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device).eval()

embedding_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/coli_protbert_embeddings.npy"
target_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/coli_mic_targets.npy"

def embed_sequence(seq):
    seq = " ".join(list(seq))
    tokens = tokenizer(seq, return_tensors="pt", truncation=True, padding='max_length', max_length=512)
    with torch.no_grad():
        output = model(**{k: v.to(device) for k, v in tokens.items()})
    return output.last_hidden_state.mean(1).squeeze().cpu().numpy()

if os.path.exists(embedding_path) and os.path.exists(target_path):
    print("Loading existing embeddings...")
    embeddings = np.load(embedding_path)
    targets = np.load(target_path)
else:
    print("Embedding sequences with ProtBERT...")
    embeddings = []
    for i, seq in enumerate(tqdm(df["Sequence"])):
        emb = embed_sequence(seq)
        embeddings.append(emb)
        if i % 100 == 0:
            np.save(embedding_path, np.vstack(embeddings))
    embeddings = np.vstack(embeddings)
    np.save(embedding_path, embeddings)
    targets = np.log1p(df["Cleaned_MIC"].values)
    np.save(target_path, targets)

"""# Aur"""

input_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/filtered_data/filtered_aur.csv"  # Update with your file path
df = pd.read_csv(input_path)
df = df.dropna(subset=["Sequence", "Cleaned_MIC"])
df["Sequence"] = df["Sequence"].str.upper().str.replace("[^ACDEFGHIKLMNPQRSTVWY]", "", regex=True)
df = df[df["Sequence"].str.len() > 10].reset_index(drop=True)

# Load ProtBERT
tokenizer = BertTokenizer.from_pretrained("Rostlab/prot_bert", do_lower_case=False)
model = BertModel.from_pretrained("Rostlab/prot_bert")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device).eval()

embedding_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/aur_protbert_embeddings.npy"
target_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/aur_mic_targets.npy"

def embed_sequence(seq):
    seq = " ".join(list(seq))
    tokens = tokenizer(seq, return_tensors="pt", truncation=True, padding='max_length', max_length=512)
    with torch.no_grad():
        output = model(**{k: v.to(device) for k, v in tokens.items()})
    return output.last_hidden_state.mean(1).squeeze().cpu().numpy()

if os.path.exists(embedding_path) and os.path.exists(target_path):
    print("Loading existing embeddings...")
    embeddings = np.load(embedding_path)
    targets = np.load(target_path)
else:
    print("Embedding sequences with ProtBERT...")
    embeddings = []
    for i, seq in enumerate(tqdm(df["Sequence"])):
        emb = embed_sequence(seq)
        embeddings.append(emb)
        if i % 100 == 0:
            np.save(embedding_path, np.vstack(embeddings))
    embeddings = np.vstack(embeddings)
    np.save(embedding_path, embeddings)
    targets = np.log1p(df["Cleaned_MIC"].values)
    np.save(target_path, targets)

"""# Arg"""

import pandas as pd
import numpy as np
from tqdm import tqdm
from transformers import BertTokenizer, BertModel
import torch
import os

input_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/filtered_data/filtered_arg.csv"  # Update with your file path
df = pd.read_csv(input_path)
df = df.dropna(subset=["Sequence", "Cleaned_MIC"])
df["Sequence"] = df["Sequence"].str.upper().str.replace("[^ACDEFGHIKLMNPQRSTVWY]", "", regex=True)
df = df[df["Sequence"].str.len() > 10].reset_index(drop=True)

# Load ProtBERT
tokenizer = BertTokenizer.from_pretrained("Rostlab/prot_bert", do_lower_case=False)
model = BertModel.from_pretrained("Rostlab/prot_bert")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device).eval()

embedding_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/arg_protbert_embeddings.npy"
target_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/arg_mic_targets.npy"

def embed_sequence(seq):
    seq = " ".join(list(seq))
    tokens = tokenizer(seq, return_tensors="pt", truncation=True, padding='max_length', max_length=512)
    with torch.no_grad():
        output = model(**{k: v.to(device) for k, v in tokens.items()})
    return output.last_hidden_state.mean(1).squeeze().cpu().numpy()

if os.path.exists(embedding_path) and os.path.exists(target_path):
    print("Loading existing embeddings...")
    embeddings = np.load(embedding_path)
    targets = np.load(target_path)
else:
    print("Embedding sequences with ProtBERT...")
    embeddings = []
    for i, seq in enumerate(tqdm(df["Sequence"])):
        emb = embed_sequence(seq)
        embeddings.append(emb)
        if i % 100 == 0:
            np.save(embedding_path, np.vstack(embeddings))
    embeddings = np.vstack(embeddings)
    np.save(embedding_path, embeddings)
    targets = np.log1p(df["Cleaned_MIC"].values)
    np.save(target_path, targets)

"""# Pne"""

import pandas as pd
import numpy as np
from tqdm import tqdm
from transformers import BertTokenizer, BertModel
import torch
import os

input_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/filtered_data/filtered_pne.csv"  # Update with your file path
df = pd.read_csv(input_path)
df = df.dropna(subset=["Sequence", "Cleaned_MIC"])
df["Sequence"] = df["Sequence"].str.upper().str.replace("[^ACDEFGHIKLMNPQRSTVWY]", "", regex=True)
df = df[df["Sequence"].str.len() > 10].reset_index(drop=True)

# Load ProtBERT
tokenizer = BertTokenizer.from_pretrained("Rostlab/prot_bert", do_lower_case=False)
model = BertModel.from_pretrained("Rostlab/prot_bert")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device).eval()

embedding_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/pne_protbert_embeddings.npy"
target_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/pne_mic_targets.npy"

def embed_sequence(seq):
    seq = " ".join(list(seq))
    tokens = tokenizer(seq, return_tensors="pt", truncation=True, padding='max_length', max_length=512)
    with torch.no_grad():
        output = model(**{k: v.to(device) for k, v in tokens.items()})
    return output.last_hidden_state.mean(1).squeeze().cpu().numpy()

if os.path.exists(embedding_path) and os.path.exists(target_path):
    print("Loading existing embeddings...")
    embeddings = np.load(embedding_path)
    targets = np.load(target_path)
else:
    print("ðŸ”„ Embedding sequences with ProtBERT...")
    embeddings = []
    for i, seq in enumerate(tqdm(df["Sequence"])):
        emb = embed_sequence(seq)
        embeddings.append(emb)
        if i % 100 == 0:
            np.save(embedding_path, np.vstack(embeddings))
    embeddings = np.vstack(embeddings)
    np.save(embedding_path, embeddings)
    targets = np.log1p(df["Cleaned_MIC"].values)
    np.save(target_path, targets)

"""# Models

## Coli
"""

embedding_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/coli_protbert_embeddings.npy"
target_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/coli_mic_targets.npy"

file_name = os.path.basename(embedding_path)
organism_code = file_name.split("_")[0].lower()
organism_names = {
    "pne": "Pneumonia",
    "aur": "Staphylococcus aureus",
    "coli": "E. coli",
    "arg": "Pseudomonas aeruginosa"
}
organism = organism_names.get(organism_code, organism_code.upper())


X = np.load(embedding_path)
y = np.load(target_path)
y_log = np.log1p(y)

X_train, X_test, y_train, y_test, y_train_log, y_test_log = train_test_split(
    X, y, y_log, test_size=0.2, random_state=42
)


scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)


results = {}
predictions = {}

def evaluate_model(model, model_name, X_train_input, X_test_input):
    model.fit(X_train_input, y_train)
    y_pred = model.predict(X_test_input)

    mse_log = mean_squared_error(y_test_log, np.log1p(y_pred))
    mse_no_log = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test_log, np.log1p(y_pred))
    mae = mean_absolute_error(y_test_log, np.log1p(y_pred))
    pearson, _ = pearsonr(y_test_log, np.log1p(y_pred))
    kendall, _ = kendalltau(y_test_log, np.log1p(y_pred))

    results[model_name] = {
        'MSE(log)': mse_log, 'MSE': mse_no_log, 'R2': r2,
        'MAE': mae, 'Pearson': pearson, 'Kendall': kendall
    }
    predictions[model_name] = y_pred

    print(f"\n{model_name} Results:")
    print(f"MSE(log): {mse_log:.4f}, MSE: {mse_no_log:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}, Pearson: {pearson:.4f}, Kendall: {kendall:.4f}")


evaluate_model(SVR(kernel='rbf'), "SVR", X_train_pca, X_test_pca)
evaluate_model(RandomForestRegressor(n_estimators=100, random_state=42), "Random Forest", X_train, X_test)
evaluate_model(xgb.XGBRegressor(objective="reg:squarederror", n_estimators=100, random_state=42), "XGBoost", X_train, X_test)
evaluate_model(MLPRegressor(hidden_layer_sizes=(512, 128), max_iter=500, random_state=42), "MLP", X_train_pca, X_test_pca)


df_results = pd.DataFrame(results).T
df_results['R2_rank'] = df_results['R2'].rank(ascending=False)
df_results['MSE_rank'] = df_results['MSE'].rank(ascending=True)
df_results['Combined_rank'] = df_results['R2_rank'] + df_results['MSE_rank']
best_model_name = df_results['Combined_rank'].idxmin()

# Save results
save_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/results/coli_model_evaluation_results.csv"
df_results.to_csv(save_path, index=True)
print(f"\nBest model based on RÂ² + MSE: {best_model_name}")
print(f"Results saved to {save_path}")


fig, axes = plt.subplots(2, 2, figsize=(14, 10))
metrics = ['MSE(log)', 'R2', 'MAE', 'Pearson']
for ax, metric in zip(axes.flatten(), metrics):
    sns.barplot(x=df_results.index, y=df_results[metric], ax=ax)
    ax.set_title(f'{metric} Comparison on {organism}')
    ax.set_ylabel(metric)
    ax.set_xlabel('Model')
    ax.set_xticklabels(df_results.index, rotation=45)
    ax.grid(True)
plt.tight_layout()
plt.show()


y_pred = predictions[best_model_name]
y_true_log = np.log1p(y_test)
y_pred_log = np.log1p(y_pred)
residuals = y_pred_log - y_true_log

# Scatter Plot
plt.figure(figsize=(6, 6))
sns.scatterplot(x=y_true_log, y=y_pred_log)
plt.plot([min(y_true_log), max(y_true_log)], [min(y_true_log), max(y_true_log)], 'r--')
plt.xlabel("True MIC (log)")
plt.ylabel("Predicted MIC (log)")
plt.title(f"{best_model_name} on {organism}: True vs. Predicted MIC (log)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Residuals
plt.figure(figsize=(6, 4))
sns.histplot(residuals, kde=True, color='purple')
plt.axvline(0, color='red', linestyle='--')
plt.title(f"{best_model_name} on {organism}: Residual Distribution (log scale)")
plt.xlabel("Residual")
plt.grid(True)
plt.tight_layout()
plt.show()

# Bland-Altman
mean_values = (y_true_log + y_pred_log) / 2
diff = y_pred_log - y_true_log
mean_diff = np.mean(diff)
std_diff = np.std(diff)

plt.figure(figsize=(6, 4))
plt.scatter(mean_values, diff, alpha=0.6)
plt.axhline(mean_diff, color='gray', linestyle='--', label="Mean Diff")
plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label="Â±1.96 SD")
plt.axhline(mean_diff - 1.96 * std_diff, color='red', linestyle='--')
plt.title(f"{best_model_name} on {organism}: Bland-Altman Plot")
plt.xlabel("Mean of True & Predicted (log MIC)")
plt.ylabel("Difference (Pred - True)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""## Aur"""

embedding_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/aur_protbert_embeddings.npy"
target_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/aur_mic_targets.npy"

file_name = os.path.basename(embedding_path)
organism_code = file_name.split("_")[0].lower()
organism_names = {
    "pne": "Pneumonia",
    "aur": "Staphylococcus aureus",
    "coli": "E. coli",
    "arg": "Pseudomonas aeruginosa"
}
organism = organism_names.get(organism_code, organism_code.upper())


X = np.load(embedding_path)
y = np.load(target_path)
y_log = np.log1p(y)

X_train, X_test, y_train, y_test, y_train_log, y_test_log = train_test_split(
    X, y, y_log, test_size=0.2, random_state=42
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)


results = {}
predictions = {}

def evaluate_model(model, model_name, X_train_input, X_test_input):
    model.fit(X_train_input, y_train)
    y_pred = model.predict(X_test_input)

    mse_log = mean_squared_error(y_test_log, np.log1p(y_pred))
    mse_no_log = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test_log, np.log1p(y_pred))
    mae = mean_absolute_error(y_test_log, np.log1p(y_pred))
    pearson, _ = pearsonr(y_test_log, np.log1p(y_pred))
    kendall, _ = kendalltau(y_test_log, np.log1p(y_pred))

    results[model_name] = {
        'MSE(log)': mse_log, 'MSE': mse_no_log, 'R2': r2,
        'MAE': mae, 'Pearson': pearson, 'Kendall': kendall
    }
    predictions[model_name] = y_pred

    print(f"\n{model_name} Results:")
    print(f"MSE(log): {mse_log:.4f}, MSE: {mse_no_log:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}, Pearson: {pearson:.4f}, Kendall: {kendall:.4f}")


print("Training and evaluating SVR...")
evaluate_model(SVR(kernel='rbf'), "SVR", X_train_pca, X_test_pca)

print("Training and evaluating Random Forest...")
evaluate_model(RandomForestRegressor(n_estimators=100, random_state=42), "Random Forest", X_train, X_test)

print("Training and evaluating XGBoost...")
evaluate_model(xgb.XGBRegressor(objective="reg:squarederror", n_estimators=100, random_state=42), "XGBoost", X_train, X_test)

print("Training and evaluating MLP...")
evaluate_model(MLPRegressor(hidden_layer_sizes=(512, 128), max_iter=500, random_state=42), "MLP", X_train_pca, X_test_pca)


df_results = pd.DataFrame(results).T
df_results['R2_rank'] = df_results['R2'].rank(ascending=False)
df_results['MSE_rank'] = df_results['MSE'].rank(ascending=True)
df_results['Combined_rank'] = df_results['R2_rank'] + df_results['MSE_rank']
best_model_name = df_results['Combined_rank'].idxmin()

save_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/results/aur_model_evaluation_results.csv"
df_results.to_csv(save_path, index=True)
print(f"\nBest model based on RÂ² + MSE: {best_model_name}")
print(f"Results saved to {save_path}")

fig, axes = plt.subplots(2, 2, figsize=(14, 10))
metrics = ['MSE(log)', 'R2', 'MAE', 'Pearson']

for ax, metric in zip(axes.flatten(), metrics):
    sns.barplot(x=df_results.index, y=df_results[metric], ax=ax)
    ax.set_title(f'{metric} Comparison on {organism}')
    ax.set_ylabel(metric)
    ax.set_xlabel('Model')
    ax.set_xticklabels(df_results.index, rotation=45)
    ax.grid(True)

plt.tight_layout()
plt.show()


y_pred = predictions[best_model_name]
y_true_log = np.log1p(y_test)
y_pred_log = np.log1p(y_pred)
residuals = y_pred_log - y_true_log

# Scatter Plot
plt.figure(figsize=(6, 6))
sns.scatterplot(x=y_true_log, y=y_pred_log)
plt.plot([min(y_true_log), max(y_true_log)], [min(y_true_log), max(y_true_log)], 'r--')
plt.xlabel("True MIC (log)")
plt.ylabel("Predicted MIC (log)")
plt.title(f"{best_model_name} on {organism}: True vs. Predicted MIC (log)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Residuals
plt.figure(figsize=(6, 4))
sns.histplot(residuals, kde=True, color='purple')
plt.axvline(0, color='red', linestyle='--')
plt.title(f"{best_model_name} on {organism}: Residual Distribution (log scale)")
plt.xlabel("Residual")
plt.grid(True)
plt.tight_layout()
plt.show()

# Bland-Altman
mean_values = (y_true_log + y_pred_log) / 2
diff = y_pred_log - y_true_log
mean_diff = np.mean(diff)
std_diff = np.std(diff)

plt.figure(figsize=(6, 4))
plt.scatter(mean_values, diff, alpha=0.6)
plt.axhline(mean_diff, color='gray', linestyle='--', label="Mean Diff")
plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label="Â±1.96 SD")
plt.axhline(mean_diff - 1.96 * std_diff, color='red', linestyle='--')
plt.title(f"{best_model_name} on {organism}: Bland-Altman Plot")
plt.xlabel("Mean of True & Predicted (log MIC)")
plt.ylabel("Difference (Pred - True)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""## Arg"""

embedding_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/arg_protbert_embeddings.npy"
target_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/arg_mic_targets.npy"

file_name = os.path.basename(embedding_path)
organism_code = file_name.split("_")[0].lower()
organism_names = {
    "pne": "Pneumonia",
    "aur": "Staphylococcus aureus",
    "coli": "E. coli",
    "arg": "Pseudomonas aeruginosa"
}
organism = organism_names.get(organism_code, organism_code.upper())


X = np.load(embedding_path)
y = np.load(target_path)
y_log = np.log1p(y)


X_train, X_test, y_train, y_test, y_train_log, y_test_log = train_test_split(
    X, y, y_log, test_size=0.2, random_state=42
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)


results = {}
predictions = {}

def evaluate_model(model, model_name, X_train_input, X_test_input):
    model.fit(X_train_input, y_train)
    y_pred = model.predict(X_test_input)

    mse_log = mean_squared_error(y_test_log, np.log1p(y_pred))
    mse_no_log = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test_log, np.log1p(y_pred))
    mae = mean_absolute_error(y_test_log, np.log1p(y_pred))
    pearson, _ = pearsonr(y_test_log, np.log1p(y_pred))
    kendall, _ = kendalltau(y_test_log, np.log1p(y_pred))

    results[model_name] = {
        'MSE(log)': mse_log, 'MSE': mse_no_log, 'R2': r2,
        'MAE': mae, 'Pearson': pearson, 'Kendall': kendall
    }

    predictions[model_name] = y_pred
    print(f"\n{model_name} Results:")
    print(f"MSE(log): {mse_log:.4f}, MSE: {mse_no_log:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}, Pearson: {pearson:.4f}, Kendall: {kendall:.4f}")


print("Training and evaluating SVR...")
evaluate_model(SVR(kernel='rbf'), "SVR", X_train_pca, X_test_pca)

print("Training and evaluating Random Forest Regressor...")
evaluate_model(RandomForestRegressor(n_estimators=100, random_state=42), "Random Forest", X_train, X_test)

print("Training and evaluating XGBoost...")
evaluate_model(xgb.XGBRegressor(objective="reg:squarederror", n_estimators=100, random_state=42), "XGBoost", X_train, X_test)

print("Training and evaluating MLP Regressor...")
evaluate_model(MLPRegressor(hidden_layer_sizes=(512, 128), max_iter=500, random_state=42), "MLP", X_train_pca, X_test_pca)


df_results = pd.DataFrame(results).T
df_results['R2_rank'] = df_results['R2'].rank(ascending=False)
df_results['MSE_rank'] = df_results['MSE'].rank(ascending=True)
df_results['Combined_rank'] = df_results['R2_rank'] + df_results['MSE_rank']
best_model_name = df_results['Combined_rank'].idxmin()

results_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/results/arg_model_evaluation_results.csv"
df_results.to_csv(results_path, index=True)
print(f"\nBest model based on RÂ² + MSE: {best_model_name}")
print(f"Results saved to: {results_path}")


fig, axes = plt.subplots(2, 2, figsize=(14, 10))
metrics = ['MSE(log)', 'R2', 'MAE', 'Pearson']

for ax, metric in zip(axes.flatten(), metrics):
    sns.barplot(x=df_results.index, y=df_results[metric], ax=ax)
    ax.set_title(f'{metric} Comparison on {organism}')
    ax.set_ylabel(metric)
    ax.set_xlabel('Model')
    ax.set_xticklabels(df_results.index, rotation=45)
    ax.grid(True)

plt.tight_layout()
plt.show()


y_pred = predictions[best_model_name]
y_true_log = np.log1p(y_test)
y_pred_log = np.log1p(y_pred)
residuals = y_pred_log - y_true_log

# Scatter Plot
plt.figure(figsize=(6, 6))
sns.scatterplot(x=y_true_log, y=y_pred_log)
plt.plot([min(y_true_log), max(y_true_log)], [min(y_true_log), max(y_true_log)], 'r--')
plt.xlabel("True MIC (log)")
plt.ylabel("Predicted MIC (log)")
plt.title(f"{best_model_name} on {organism}: True vs. Predicted MIC (log)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Residual Plot
plt.figure(figsize=(6, 4))
sns.histplot(residuals, kde=True, color='purple')
plt.axvline(0, color='red', linestyle='--')
plt.title(f"{best_model_name} on {organism}: Residual Distribution (log scale)")
plt.xlabel("Residual")
plt.grid(True)
plt.tight_layout()
plt.show()

# Bland-Altman Plot
mean_values = (y_true_log + y_pred_log) / 2
diff = y_pred_log - y_true_log
mean_diff = np.mean(diff)
std_diff = np.std(diff)

plt.figure(figsize=(6, 4))
plt.scatter(mean_values, diff, alpha=0.6)
plt.axhline(mean_diff, color='gray', linestyle='--', label="Mean Diff")
plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label="Â±1.96 SD")
plt.axhline(mean_diff - 1.96 * std_diff, color='red', linestyle='--')
plt.title(f"{best_model_name} on {organism}: Bland-Altman Plot")
plt.xlabel("Mean of True & Predicted (log MIC)")
plt.ylabel("Difference (Pred - True)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""## Pne"""

embedding_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/pne_protbert_embeddings.npy"
target_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/emb/pne_mic_targets.npy"

file_name = os.path.basename(embedding_path)
organism_code = file_name.split("_")[0].lower()
organism_names = {
    "pne": "Pneumonia",
    "aur": "Staphylococcus aureus",
    "coli": "E. coli",
    "arg": "Pseudomonas aeruginosa"
}
organism = organism_names.get(organism_code, organism_code.upper())


X = np.load(embedding_path)
y = np.load(target_path)
y_log = np.log1p(y)


X_train, X_test, y_train, y_test, y_train_log, y_test_log = train_test_split(
    X, y, y_log, test_size=0.2, random_state=42
)


scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)


results = {}
predictions = {}

def evaluate_model(model, model_name, X_train_input, X_test_input):
    model.fit(X_train_input, y_train)
    y_pred = model.predict(X_test_input)

    mse_log = mean_squared_error(y_test_log, np.log1p(y_pred))
    mse_no_log = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test_log, np.log1p(y_pred))
    mae = mean_absolute_error(y_test_log, np.log1p(y_pred))
    pearson, _ = pearsonr(y_test_log, np.log1p(y_pred))
    kendall, _ = kendalltau(y_test_log, np.log1p(y_pred))

    results[model_name] = {
        'MSE(log)': mse_log, 'MSE': mse_no_log, 'R2': r2,
        'MAE': mae, 'Pearson': pearson, 'Kendall': kendall
    }
    predictions[model_name] = y_pred

    print(f"\n{model_name} Results:")
    print(f"MSE(log): {mse_log:.4f}, MSE: {mse_no_log:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}, Pearson: {pearson:.4f}, Kendall: {kendall:.4f}")


print("Training and evaluating SVR...")
evaluate_model(SVR(kernel='rbf'), "SVR", X_train_pca, X_test_pca)

print("Training and evaluating Random Forest Regressor...")
evaluate_model(RandomForestRegressor(n_estimators=100, random_state=42), "Random Forest", X_train, X_test)

print("Training and evaluating XGBoost...")
evaluate_model(xgb.XGBRegressor(objective="reg:squarederror", n_estimators=100, random_state=42), "XGBoost", X_train, X_test)

print("Training and evaluating MLP Regressor...")
evaluate_model(MLPRegressor(hidden_layer_sizes=(512, 128), max_iter=500, random_state=42), "MLP", X_train_pca, X_test_pca)

df_results = pd.DataFrame(results).T
df_results['R2_rank'] = df_results['R2'].rank(ascending=False)
df_results['MSE_rank'] = df_results['MSE'].rank(ascending=True)
df_results['Combined_rank'] = df_results['R2_rank'] + df_results['MSE_rank']
best_model_name = df_results['Combined_rank'].idxmin()

results_path = "/content/drive/MyDrive/AMPs/Project Data/Regression Part/results/pne_model_evaluation_results.csv"
df_results.to_csv(results_path, index=True)
print(f"\nBest model based on RÂ² + MSE: {best_model_name}")
print(f"Results saved to: {results_path}")


fig, axes = plt.subplots(2, 2, figsize=(14, 10))
metrics = ['MSE(log)', 'R2', 'MAE', 'Pearson']

for ax, metric in zip(axes.flatten(), metrics):
    sns.barplot(x=df_results.index, y=df_results[metric], ax=ax)
    ax.set_title(f'{metric} Comparison on {organism}')
    ax.set_ylabel(metric)
    ax.set_xlabel('Model')
    ax.set_xticklabels(df_results.index, rotation=45)
    ax.grid(True)

plt.tight_layout()
plt.show()


y_pred = predictions[best_model_name]
y_true_log = np.log1p(y_test)
y_pred_log = np.log1p(y_pred)
residuals = y_pred_log - y_true_log

# Scatter Plot
plt.figure(figsize=(6, 6))
sns.scatterplot(x=y_true_log, y=y_pred_log)
plt.plot([min(y_true_log), max(y_true_log)], [min(y_true_log), max(y_true_log)], 'r--')
plt.xlabel("True MIC (log)")
plt.ylabel("Predicted MIC (log)")
plt.title(f"{best_model_name} on {organism}: True vs. Predicted MIC (log)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Residuals Plot
plt.figure(figsize=(6, 4))
sns.histplot(residuals, kde=True, color='purple')
plt.axvline(0, color='red', linestyle='--')
plt.title(f"{best_model_name} on {organism}: Residual Distribution (log scale)")
plt.xlabel("Residual")
plt.grid(True)
plt.tight_layout()
plt.show()

# Bland-Altman Plot
mean_values = (y_true_log + y_pred_log) / 2
diff = y_pred_log - y_true_log
mean_diff = np.mean(diff)
std_diff = np.std(diff)

plt.figure(figsize=(6, 4))
plt.scatter(mean_values, diff, alpha=0.6)
plt.axhline(mean_diff, color='gray', linestyle='--', label="Mean Diff")
plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label="Â±1.96 SD")
plt.axhline(mean_diff - 1.96 * std_diff, color='red', linestyle='--')
plt.title(f"{best_model_name} on {organism}: Bland-Altman Plot")
plt.xlabel("Mean of True & Predicted (log MIC)")
plt.ylabel("Difference (Pred - True)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()